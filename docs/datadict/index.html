<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.1" />
<title>datadict API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>datadict</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import pandas as pd
import numpy as np
import warnings
import os
import functools
from os import path
from pandas.api.types import is_numeric_dtype
from typing import Dict


class DataDict:
    &#34;&#34;&#34;
    This class provides functionality for mapping the columns of different data frames into a consistent namespace,
    ensuring the columns to comply with the data type specified in the data dictionary and describing the data.

    The data dictionary consists at least of the following columns:
    * `Data Set`: Used when mapping in combination with `Field` to rename to the column to `Name`.
    * `Field`: Column name of the data frame to map to `Name`.
    * `Name`: Column name that is unique throughout the data dictionary.
    * `Description`: Description of the column name. This can be used to provide additional information when displaying the data frame.
    * `Type`: Type the column should be cast to.
    * `Format`: Format to use when values need to be converted to a string representation. The format string has to be a Python format string such as `{:.0f}%`

    The data dictionary can either be loaded from a CSV file or from a data frame.
    &#34;&#34;&#34;

    _data_dict_file: str
    _data_dict_updated: float = None
    _data_dict: pd.DataFrame
    _formats: dict
    _names: list

    auto_reload: bool
    column_names = [&#39;Data Set&#39;, &#39;Field&#39;, &#39;Name&#39;, &#39;Description&#39;, &#39;Type&#39;, &#39;Format&#39;]
    supported_types = [&#39;float&#39;, &#39;float32&#39;, &#39;float64&#39;, &#39;int&#39;, &#39;int32&#39;, &#39;int64&#39;, &#39;object&#39;, &#39;str&#39;, &#39;bool&#39;, &#39;datetime64&#39;, &#39;timedelta&#39;, &#39;category&#39;]
    stats = {&#39;sum&#39;: &#39;Total&#39;, &#39;mean&#39;: &#39;Average&#39;}
    meta: object

    def auto_reload(func):
        @functools.wraps(func)
        def wrapper(self, *args, **kwargs):
            if self.auto_reload:
                self.__load()

            return func(self, *args, **kwargs)

        return wrapper

    def __aggr(self, series: pd.Series):
        funcs = self._data_dict[self._data_dict[&#39;Name&#39;] == series.name][&#39;Default Aggregation&#39;].values
        try:
            return eval(&#39;series.&#39; + funcs[0]) if len(funcs) == 1 and not funcs[0].isspace() else None
        except:
            return None

    @property
    def data_dict(self) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Data dictionary as a data frame.
        &#34;&#34;&#34;
        return self._data_dict

    @property
    def formats(self) -&gt; Dict[str, str]:
        &#34;&#34;&#34;
        Dictionary that maps the columns to names to their format strings.
        &#34;&#34;&#34;
        return self._formats

    def __init__(self, data_dict_file: str = None, auto_reload: bool = True, data_dict: pd.DataFrame = None):
        &#34;&#34;&#34;
        Creates the data dictionary and validates it. It can either be initialised from a CSV file or a data frame.

        Args:
            data_dict_file: The data dictionary file in CSV format to use to initialise the data dictionary.
            auto_reload: Whether the data dictionary should automatically check for changes in the data dictionary file.
            data_dict: The data dictionary as a data frame to use to initialise the data dictionary instead of the data dictionary file.
        &#34;&#34;&#34;
        if data_dict_file is not None and data_dict is not None:
            raise ValueError(&#39;Parameters data_dict_file and data_dict can\&#39;t be assigned at the same time.&#39;)

        self._data_dict_file = data_dict_file
        self.auto_reload = auto_reload
        self.__set_data_dict(data_dict)

        self.__load()

    def __load(self) -&gt; None:
        &#34;&#34;&#34;
        Loads the data dictionary from the CSV file specified during initialisation and validates it.
        &#34;&#34;&#34;
        if self._data_dict_file is None:
            return

        if not path.exists(self._data_dict_file):
            raise ValueError(f&#39;The data dictionary file {self._data_dict_file} does not exist.&#39;)

        if self._data_dict_updated is not None and os.path.getmtime(self._data_dict_file) == self._data_dict_updated:
            return

        data_dict = pd.read_csv(self._data_dict_file)
        self._data_dict_updated = os.path.getmtime(self._data_dict_file)

        self.__set_data_dict(data_dict)

    def __set_data_dict(self, data_dict: pd.DataFrame) -&gt; None:
        &#34;&#34;&#34;
        Sets a new data dictionary frame validates it.

        Args:
            data_dict: Specifies the data dictionary.
        &#34;&#34;&#34;
        DataDict.validate(data_dict)

        self._data_dict = data_dict

        if not data_dict is None:
            formats = self._data_dict[[&#39;Name&#39;, &#39;Format&#39;]].dropna(subset=[&#39;Format&#39;])
            self._formats = pd.Series(formats[&#39;Format&#39;].values, index=formats[&#39;Name&#39;]).to_dict()
            self._names = list(self._data_dict[&#39;Name&#39;].values)

    @staticmethod
    def validate(data_dict: pd.DataFrame) -&gt; None:
        &#34;&#34;&#34;
        Validates the given data dictionary and raises a `ValueError` if the validation fails.

        Args:
            data_dict: The data dictionary to validate.

        Returns:

        Raises:
            ValueError: If the given data dictionary is not valid.
        &#34;&#34;&#34;
        if data_dict is None:
            return

        data_dict = data_dict.copy()

        # Check that all expected columns exist.
        if not set(data_dict.columns) &gt;= set(DataDict.column_names):
            raise ValueError(f&#39;The data dictionary must at least include the following column names: {DataDict.column_names}&#39;)

        # Check that all types are supported Python types.
        if not set(data_dict[&#39;Type&#39;].values) &lt;= set(DataDict.supported_types):
            raise ValueError(
                f&#39;The Type column of the data dictionary contains the following unsupported types {set(data_dict[&#34;Type&#34;].values) - set(DataDict.supported_types)}. Only the following types are supported: {DataDict.supported_types}&#39;)

        # Check that names are unique.
        if any(data_dict[&#39;Name&#39;].duplicated()):
            raise ValueError(f&#39;The Name column contains the following duplicates: {data_dict[&#34;Name&#34;][data_dict[&#34;Name&#34;].duplicated()].values}. The names must be unique.&#39;)

        # Check that dataset and field combination is unique.
        data_dict = data_dict.replace(&#39;&#39;, np.nan)
        data_dict[&#39;Field ID&#39;] = data_dict[&#39;Data Set&#39;] + &#39;.&#39; + data_dict[&#39;Field&#39;]
        if any(data_dict[&#39;Field ID&#39;][data_dict[&#39;Field ID&#39;].isnull() == False].duplicated()):
            raise ValueError(f&#39;The combination of columns Data Set and Field contains the following duplicates: {data_dict[&#34;Field ID&#34;][data_dict[&#34;Field ID&#34;].duplicated()].values}. The combination must be unique.&#39;)

    def __str_to_bool(self, value: str) -&gt; object:
        &#34;&#34;&#34;
        Converts the given string to a bool if the argument is a string otherwise it returns the value untouched. `yes`, `true`, `1` are considered `True`, the rest is considered `False`.

        Args:
            value: The value to convert to a bool.

        Returns:
            The converted bool if the value is a string. Otherwise the value passed in the argument.
        &#34;&#34;&#34;
        if pd.isnull(value):
            return None

        if not isinstance(value, str):
            return value

        return value.lower() in [&#39;yes&#39;, &#39;true&#39;, &#39;1&#39;]

    def df(self, data_set: str = None, any_data_set: bool = False) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Gets the data set with the given name as a data frame.

        Args:
            data_set: The data set to filter by. If this value matches a value in the `Data Set` column of the data dictionary, the matching rows are returned.
            If `data_set` is not specified, the entries with empty `Data Set` are returned.
            any_data_set: Whether to return all data sets in the data frame.

        Returns:
            The data set as a data frame, index by the `Field` column.
        &#34;&#34;&#34;
        if any_data_set and data_set is not None:
            raise ValueError(&#39;Either data_set can be provide or any_data_set can be True but not both.&#39;)

        if data_set is None: data_set = &#39;&#39;

        return self._data_dict[(self._data_dict[&#39;Data Set&#39;] == data_set) | any_data_set].set_index(&#39;Field&#39;)

    @auto_reload
    def remap(self, df: pd.DataFrame, data_set: str = None, ensure_cols: bool = False) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Renames the columns in the given data frame based on based on the `Data Set` and `Field` attributes in the data dictionary to `Name`
        if such a mapping found and converts the columns data to `Type`. It also reorders the columns based on the order of the data dictionary entries.

        Args:
            df: The data frame to remap.
            data_set: The data set to use. If this value matches a value in the `Data Set` column of the data dictionary, then the corresponding names in the `Field`
                column are used to rename the columns of the given data frame to the `Name` column name. If `dataset` is not specified, the values in `Field` column
                that have entries with empty `Data Set` are used.
            ensure_cols: Ensures all columns in the data_set are present. If the source data frame does not contain them, empty ones are created. This parameter can
                only be true if data_set is specified. This is useful when the data frame to be remapped may not have all the columns if it is empty.

        Returns:
            The remapped data frame.
        &#34;&#34;&#34;
        if df is None:
            raise ValueError(&#39;Parameter df not provided.&#39;)

        if (data_set is None or data_set == &#39;&#39;) and ensure_cols:
            raise ValueError(&#39;Parameter data_set cannot be None or empty if ensure_cols is True.&#39;)

        dd = self.df(data_set)

        # Ensure that nan is represented as None so that column type conversion does not result in object types if nan is present.
        df = df.replace(&#39;&#39;, np.nan)

        types_map = dd[&#39;Type&#39;].to_dict()
        types_map = {col: type for (col, type) in types_map.items() if col in df.columns}  # Remove mapping for columns that are not present in data frame.

        # Treat bool separately &#39;cause all non-empty strings are converted to True.
        # Map values of non-bool columns using data type.
        no_bool_types_map = {col: type for (col, type) in types_map.items() if type != &#39;bool&#39;}
        df = df.astype(no_bool_types_map, errors=&#39;ignore&#39;)

        # Map values of bool columns using data type.
        bool_cols = [col for (col, type) in types_map.items() if type == &#39;bool&#39;]
        df[bool_cols] = df[bool_cols].apply(lambda col: col.map(lambda val: self.__str_to_bool(val)))

        columns_map = dd[&#39;Name&#39;].to_dict()
        df = df.rename(columns=columns_map)
        df = self.reorder(df)

        if ensure_cols:
            df = self.ensure_cols(df, data_set=data_set)

        return df

    @auto_reload
    def reorder(self, df: pd.DataFrame) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Reorders the given data frame based on the order of the matching entries in the data dictionary.

        Args:
            df: The data frame whose columns need to be reordered.

        Returns:
            The reordered data frame.
        &#34;&#34;&#34;
        return df[[x for x in self._names if x in list(df.columns.values)]
                  + [x for x in list(df.columns.values) if x not in self._names]]

    @auto_reload
    def ensure_cols(self, df: pd.DataFrame, cols: list = None, data_set: str = None) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Ensures that the columns from the given data set or the given columns names are present the resulting data frame. Missing columns are added at the end.

        Args:
            df: The data frame to add the missing columns (if any) to.
            data_set: The name of data set to use. If this value matches a value in the `Data Set` column of the data dictionary, then `Name` column is used to identify missing columns. If `dataset` is not specified, the values in `Name` column
                that have entries with empty `Data Set` are used.
            cols: The column names to ensure are present in the returned data frame.

        Returns:
            The data frame with missing columns added to the end.
        &#34;&#34;&#34;
        if cols is not None and data_set is not None:
            raise ValueError(&#39;Either the cols or the data_set arguments can be provided but not both.&#39;)

        if cols is None:
            cols = list(self.df(data_set)[&#39;Name&#39;].values)

        current_cols = list(df.columns.values)+list(df.index.names)
        missing_cols = [v for v in cols if v not in current_cols]
        return df.reindex(columns=(list(df.columns.values)+missing_cols))

    @auto_reload
    def strip_cols(self, df: pd.DataFrame, data_set: str = None, any_data_set: bool = False):
        &#34;&#34;&#34;
        Removes all columns that are not in the given data set from the given data frame or all columns that are not in any data set. It leaves
        the index untouched.

        Args:
            df: The data frame to remove the columns from.
            data_set: The name of the data set with columns to preserve.
            any_data_set: Whether to remove all columns that are not in any data set.

        Returns:
            The data frame is only the data set columns.
        &#34;&#34;&#34;
        if any_data_set and data_set is not None:
            raise ValueError(&#39;Either data_set can be provide or any_data_set can be True but not both.&#39;)

        ds_cols = list(self.df(data_set, any_data_set)[&#39;Name&#39;].values)
        df_cols = [v for v in df.columns if v in ds_cols]
        return df[df_cols]

    def add_stats(self, df: pd.DataFrame) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Adds the `Total` and `Average` of the column values as two rows at the top of the data frame.

        Args:
            df: The data frame to summarise.

        Returns:
            The data frame with the `Total` and `Average` at the top.
        &#34;&#34;&#34;
        if df is None: raise ValueError(&#39;Parameter df is mandatory&#39;)

        num_agg_map = {col: DataDict.stats.keys() for col in df if is_numeric_dtype(df[col]) and df[col].dtype != np.bool}
        aggr_row = df.agg(num_agg_map).rename(DataDict.stats)
        if len(df.index.names) &gt; 1:
            aggr_row = pd.concat([aggr_row], keys=[np.nan] * len(DataDict.stats.keys()), names=df.index.names[1:])
        df = pd.concat([df.iloc[:0], aggr_row, df], sort=False)

        # Adds the dictionary of stats to the data frame.
        if not hasattr(df, &#39;stats&#39;):
            with warnings.catch_warnings():
                warnings.simplefilter(&#34;ignore&#34;)
                df.stats = {}

        df.stats = {**df.stats, **DataDict.stats}

        return df

    def has_stats(self, df: pd.DataFrame):
        &#34;&#34;&#34;
        Checks whether the given data frame has stats rows added at the top of the data frame.

        Args:
            df: The data frame to check.

        Returns:
            Whether the given data frame has stats.
        &#34;&#34;&#34;
        return hasattr(df, &#39;stats&#39;)

    def format(self, df: pd.DataFrame) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Formats the data frame based on the `Format` attribute in the data dictionary.

        Args:
            df: The data frame to format.

        Returns:
            The formatted data frame.
        &#34;&#34;&#34;
        if df is None: raise ValueError(&#39;Parameter df is mandatory&#39;)

        # Necessary to define separate function instead of using lambda directly (see https://stackoverflow.com/questions/36805071/dictionary-comprehension-with-lambda-functions-gives-wrong-results)
        def make_func(f: str = None):
            def format_value(x):
                if f is None or f == &#39;&#39;:
                    return x if not pd.isnull(x) else &#39;-&#39;

                return f.format(x) if not pd.isnull(x) else &#39;-&#39;

            # If mean is part of the stats, then the integer numbers need to be formatted as floats because the mean of integers can be float.
            if self.has_stats(df) and &#39;mean&#39; in df.stats.keys() and not f is None:
                f = f.replace(&#39;:d&#39;, &#39;:.1f&#39;)

            return lambda x: format_value(x)

        # Assembles a dictionary with columns as key and format functions as values but only for the columns that are actually in the data frame.
        formats = {col: make_func(f) for (col, f) in self._formats.items() if col in df.columns.values}
        formats = {**formats, **{col: make_func() for col in set(df.columns.values) - set(self._formats.keys())}}

        df = df.copy()
        for col, value in formats.items():
            try:
                df[col] = df[col].apply(value)
            except ValueError as e:
                warnings.warn(f&#39;A value in column {col} could not be formatted.\nError message: {e}&#39;)

        return df


DataDict.meta = DataDict(data_dict=pd.DataFrame.from_dict(orient=&#39;index&#39;,
                                                          data={0: [&#39;data_dict&#39;, &#39;data_set&#39;, &#39;Data Set&#39;, &#39;Used when mapping in combination with Field to rename to the column to Name.&#39;, &#39;str&#39;, &#39;{:s}&#39;],
                                                                1: [&#39;data_dict&#39;, &#39;field&#39;, &#39;Field&#39;, &#39;Column name of the data frame to map to Name.&#39;, &#39;str&#39;, &#39;{:s}&#39;],
                                                                2: [&#39;data_dict&#39;, &#39;name&#39;, &#39;Name&#39;, &#39;Column name that is unique throughout the data dictionary.&#39;, &#39;str&#39;, &#39;{:s}&#39;],
                                                                3: [&#39;data_dict&#39;, &#39;description&#39;, &#39;Description&#39;, &#39;Description of the column name. This can be used to provide additional information when displaying the data frame.&#39;, &#39;str&#39;,
                                                                    &#39;{:s}&#39;],
                                                                4: [&#39;data_dict&#39;, &#39;type&#39;, &#39;Type&#39;, &#39;Type the column should be cast to.&#39;, &#39;str&#39;, &#39;{:s}&#39;],
                                                                5: [&#39;data_dict&#39;, &#39;format&#39;, &#39;Format&#39;,
                                                                    &#39;Format to use when values need to be converted to a string representation. The format string has to be a Python format string such as {:.0f}%&#39;, &#39;str&#39;, &#39;{:s}&#39;]},
                                                          columns=[&#39;Data Set&#39;, &#39;Field&#39;, &#39;Name&#39;, &#39;Description&#39;, &#39;Type&#39;, &#39;Format&#39;]))</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="datadict.jupyter" href="jupyter/index.html">datadict.jupyter</a></code></dt>
<dd>
<section class="desc"></section>
</dd>
</dl>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="datadict.DataDict"><code class="flex name class">
<span>class <span class="ident">DataDict</span></span>
<span>(</span><span>data_dict_file=None, auto_reload=True, data_dict=None)</span>
</code></dt>
<dd>
<section class="desc"><p>This class provides functionality for mapping the columns of different data frames into a consistent namespace,
ensuring the columns to comply with the data type specified in the data dictionary and describing the data.</p>
<p>The data dictionary consists at least of the following columns:
* <code>Data Set</code>: Used when mapping in combination with <code>Field</code> to rename to the column to <code>Name</code>.
* <code>Field</code>: Column name of the data frame to map to <code>Name</code>.
* <code>Name</code>: Column name that is unique throughout the data dictionary.
* <code>Description</code>: Description of the column name. This can be used to provide additional information when displaying the data frame.
* <code>Type</code>: Type the column should be cast to.
* <code>Format</code>: Format to use when values need to be converted to a string representation. The format string has to be a Python format string such as <code>{:.0f}%</code></p>
<p>The data dictionary can either be loaded from a CSV file or from a data frame.</p>
<p>Creates the data dictionary and validates it. It can either be initialised from a CSV file or a data frame.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data_dict_file</code></strong></dt>
<dd>The data dictionary file in CSV format to use to initialise the data dictionary.</dd>
<dt><strong><code>auto_reload</code></strong></dt>
<dd>Whether the data dictionary should automatically check for changes in the data dictionary file.</dd>
<dt><strong><code>data_dict</code></strong></dt>
<dd>The data dictionary as a data frame to use to initialise the data dictionary instead of the data dictionary file.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DataDict:
    &#34;&#34;&#34;
    This class provides functionality for mapping the columns of different data frames into a consistent namespace,
    ensuring the columns to comply with the data type specified in the data dictionary and describing the data.

    The data dictionary consists at least of the following columns:
    * `Data Set`: Used when mapping in combination with `Field` to rename to the column to `Name`.
    * `Field`: Column name of the data frame to map to `Name`.
    * `Name`: Column name that is unique throughout the data dictionary.
    * `Description`: Description of the column name. This can be used to provide additional information when displaying the data frame.
    * `Type`: Type the column should be cast to.
    * `Format`: Format to use when values need to be converted to a string representation. The format string has to be a Python format string such as `{:.0f}%`

    The data dictionary can either be loaded from a CSV file or from a data frame.
    &#34;&#34;&#34;

    _data_dict_file: str
    _data_dict_updated: float = None
    _data_dict: pd.DataFrame
    _formats: dict
    _names: list

    auto_reload: bool
    column_names = [&#39;Data Set&#39;, &#39;Field&#39;, &#39;Name&#39;, &#39;Description&#39;, &#39;Type&#39;, &#39;Format&#39;]
    supported_types = [&#39;float&#39;, &#39;float32&#39;, &#39;float64&#39;, &#39;int&#39;, &#39;int32&#39;, &#39;int64&#39;, &#39;object&#39;, &#39;str&#39;, &#39;bool&#39;, &#39;datetime64&#39;, &#39;timedelta&#39;, &#39;category&#39;]
    stats = {&#39;sum&#39;: &#39;Total&#39;, &#39;mean&#39;: &#39;Average&#39;}
    meta: object

    def auto_reload(func):
        @functools.wraps(func)
        def wrapper(self, *args, **kwargs):
            if self.auto_reload:
                self.__load()

            return func(self, *args, **kwargs)

        return wrapper

    def __aggr(self, series: pd.Series):
        funcs = self._data_dict[self._data_dict[&#39;Name&#39;] == series.name][&#39;Default Aggregation&#39;].values
        try:
            return eval(&#39;series.&#39; + funcs[0]) if len(funcs) == 1 and not funcs[0].isspace() else None
        except:
            return None

    @property
    def data_dict(self) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Data dictionary as a data frame.
        &#34;&#34;&#34;
        return self._data_dict

    @property
    def formats(self) -&gt; Dict[str, str]:
        &#34;&#34;&#34;
        Dictionary that maps the columns to names to their format strings.
        &#34;&#34;&#34;
        return self._formats

    def __init__(self, data_dict_file: str = None, auto_reload: bool = True, data_dict: pd.DataFrame = None):
        &#34;&#34;&#34;
        Creates the data dictionary and validates it. It can either be initialised from a CSV file or a data frame.

        Args:
            data_dict_file: The data dictionary file in CSV format to use to initialise the data dictionary.
            auto_reload: Whether the data dictionary should automatically check for changes in the data dictionary file.
            data_dict: The data dictionary as a data frame to use to initialise the data dictionary instead of the data dictionary file.
        &#34;&#34;&#34;
        if data_dict_file is not None and data_dict is not None:
            raise ValueError(&#39;Parameters data_dict_file and data_dict can\&#39;t be assigned at the same time.&#39;)

        self._data_dict_file = data_dict_file
        self.auto_reload = auto_reload
        self.__set_data_dict(data_dict)

        self.__load()

    def __load(self) -&gt; None:
        &#34;&#34;&#34;
        Loads the data dictionary from the CSV file specified during initialisation and validates it.
        &#34;&#34;&#34;
        if self._data_dict_file is None:
            return

        if not path.exists(self._data_dict_file):
            raise ValueError(f&#39;The data dictionary file {self._data_dict_file} does not exist.&#39;)

        if self._data_dict_updated is not None and os.path.getmtime(self._data_dict_file) == self._data_dict_updated:
            return

        data_dict = pd.read_csv(self._data_dict_file)
        self._data_dict_updated = os.path.getmtime(self._data_dict_file)

        self.__set_data_dict(data_dict)

    def __set_data_dict(self, data_dict: pd.DataFrame) -&gt; None:
        &#34;&#34;&#34;
        Sets a new data dictionary frame validates it.

        Args:
            data_dict: Specifies the data dictionary.
        &#34;&#34;&#34;
        DataDict.validate(data_dict)

        self._data_dict = data_dict

        if not data_dict is None:
            formats = self._data_dict[[&#39;Name&#39;, &#39;Format&#39;]].dropna(subset=[&#39;Format&#39;])
            self._formats = pd.Series(formats[&#39;Format&#39;].values, index=formats[&#39;Name&#39;]).to_dict()
            self._names = list(self._data_dict[&#39;Name&#39;].values)

    @staticmethod
    def validate(data_dict: pd.DataFrame) -&gt; None:
        &#34;&#34;&#34;
        Validates the given data dictionary and raises a `ValueError` if the validation fails.

        Args:
            data_dict: The data dictionary to validate.

        Returns:

        Raises:
            ValueError: If the given data dictionary is not valid.
        &#34;&#34;&#34;
        if data_dict is None:
            return

        data_dict = data_dict.copy()

        # Check that all expected columns exist.
        if not set(data_dict.columns) &gt;= set(DataDict.column_names):
            raise ValueError(f&#39;The data dictionary must at least include the following column names: {DataDict.column_names}&#39;)

        # Check that all types are supported Python types.
        if not set(data_dict[&#39;Type&#39;].values) &lt;= set(DataDict.supported_types):
            raise ValueError(
                f&#39;The Type column of the data dictionary contains the following unsupported types {set(data_dict[&#34;Type&#34;].values) - set(DataDict.supported_types)}. Only the following types are supported: {DataDict.supported_types}&#39;)

        # Check that names are unique.
        if any(data_dict[&#39;Name&#39;].duplicated()):
            raise ValueError(f&#39;The Name column contains the following duplicates: {data_dict[&#34;Name&#34;][data_dict[&#34;Name&#34;].duplicated()].values}. The names must be unique.&#39;)

        # Check that dataset and field combination is unique.
        data_dict = data_dict.replace(&#39;&#39;, np.nan)
        data_dict[&#39;Field ID&#39;] = data_dict[&#39;Data Set&#39;] + &#39;.&#39; + data_dict[&#39;Field&#39;]
        if any(data_dict[&#39;Field ID&#39;][data_dict[&#39;Field ID&#39;].isnull() == False].duplicated()):
            raise ValueError(f&#39;The combination of columns Data Set and Field contains the following duplicates: {data_dict[&#34;Field ID&#34;][data_dict[&#34;Field ID&#34;].duplicated()].values}. The combination must be unique.&#39;)

    def __str_to_bool(self, value: str) -&gt; object:
        &#34;&#34;&#34;
        Converts the given string to a bool if the argument is a string otherwise it returns the value untouched. `yes`, `true`, `1` are considered `True`, the rest is considered `False`.

        Args:
            value: The value to convert to a bool.

        Returns:
            The converted bool if the value is a string. Otherwise the value passed in the argument.
        &#34;&#34;&#34;
        if pd.isnull(value):
            return None

        if not isinstance(value, str):
            return value

        return value.lower() in [&#39;yes&#39;, &#39;true&#39;, &#39;1&#39;]

    def df(self, data_set: str = None, any_data_set: bool = False) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Gets the data set with the given name as a data frame.

        Args:
            data_set: The data set to filter by. If this value matches a value in the `Data Set` column of the data dictionary, the matching rows are returned.
            If `data_set` is not specified, the entries with empty `Data Set` are returned.
            any_data_set: Whether to return all data sets in the data frame.

        Returns:
            The data set as a data frame, index by the `Field` column.
        &#34;&#34;&#34;
        if any_data_set and data_set is not None:
            raise ValueError(&#39;Either data_set can be provide or any_data_set can be True but not both.&#39;)

        if data_set is None: data_set = &#39;&#39;

        return self._data_dict[(self._data_dict[&#39;Data Set&#39;] == data_set) | any_data_set].set_index(&#39;Field&#39;)

    @auto_reload
    def remap(self, df: pd.DataFrame, data_set: str = None, ensure_cols: bool = False) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Renames the columns in the given data frame based on based on the `Data Set` and `Field` attributes in the data dictionary to `Name`
        if such a mapping found and converts the columns data to `Type`. It also reorders the columns based on the order of the data dictionary entries.

        Args:
            df: The data frame to remap.
            data_set: The data set to use. If this value matches a value in the `Data Set` column of the data dictionary, then the corresponding names in the `Field`
                column are used to rename the columns of the given data frame to the `Name` column name. If `dataset` is not specified, the values in `Field` column
                that have entries with empty `Data Set` are used.
            ensure_cols: Ensures all columns in the data_set are present. If the source data frame does not contain them, empty ones are created. This parameter can
                only be true if data_set is specified. This is useful when the data frame to be remapped may not have all the columns if it is empty.

        Returns:
            The remapped data frame.
        &#34;&#34;&#34;
        if df is None:
            raise ValueError(&#39;Parameter df not provided.&#39;)

        if (data_set is None or data_set == &#39;&#39;) and ensure_cols:
            raise ValueError(&#39;Parameter data_set cannot be None or empty if ensure_cols is True.&#39;)

        dd = self.df(data_set)

        # Ensure that nan is represented as None so that column type conversion does not result in object types if nan is present.
        df = df.replace(&#39;&#39;, np.nan)

        types_map = dd[&#39;Type&#39;].to_dict()
        types_map = {col: type for (col, type) in types_map.items() if col in df.columns}  # Remove mapping for columns that are not present in data frame.

        # Treat bool separately &#39;cause all non-empty strings are converted to True.
        # Map values of non-bool columns using data type.
        no_bool_types_map = {col: type for (col, type) in types_map.items() if type != &#39;bool&#39;}
        df = df.astype(no_bool_types_map, errors=&#39;ignore&#39;)

        # Map values of bool columns using data type.
        bool_cols = [col for (col, type) in types_map.items() if type == &#39;bool&#39;]
        df[bool_cols] = df[bool_cols].apply(lambda col: col.map(lambda val: self.__str_to_bool(val)))

        columns_map = dd[&#39;Name&#39;].to_dict()
        df = df.rename(columns=columns_map)
        df = self.reorder(df)

        if ensure_cols:
            df = self.ensure_cols(df, data_set=data_set)

        return df

    @auto_reload
    def reorder(self, df: pd.DataFrame) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Reorders the given data frame based on the order of the matching entries in the data dictionary.

        Args:
            df: The data frame whose columns need to be reordered.

        Returns:
            The reordered data frame.
        &#34;&#34;&#34;
        return df[[x for x in self._names if x in list(df.columns.values)]
                  + [x for x in list(df.columns.values) if x not in self._names]]

    @auto_reload
    def ensure_cols(self, df: pd.DataFrame, cols: list = None, data_set: str = None) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Ensures that the columns from the given data set or the given columns names are present the resulting data frame. Missing columns are added at the end.

        Args:
            df: The data frame to add the missing columns (if any) to.
            data_set: The name of data set to use. If this value matches a value in the `Data Set` column of the data dictionary, then `Name` column is used to identify missing columns. If `dataset` is not specified, the values in `Name` column
                that have entries with empty `Data Set` are used.
            cols: The column names to ensure are present in the returned data frame.

        Returns:
            The data frame with missing columns added to the end.
        &#34;&#34;&#34;
        if cols is not None and data_set is not None:
            raise ValueError(&#39;Either the cols or the data_set arguments can be provided but not both.&#39;)

        if cols is None:
            cols = list(self.df(data_set)[&#39;Name&#39;].values)

        current_cols = list(df.columns.values)+list(df.index.names)
        missing_cols = [v for v in cols if v not in current_cols]
        return df.reindex(columns=(list(df.columns.values)+missing_cols))

    @auto_reload
    def strip_cols(self, df: pd.DataFrame, data_set: str = None, any_data_set: bool = False):
        &#34;&#34;&#34;
        Removes all columns that are not in the given data set from the given data frame or all columns that are not in any data set. It leaves
        the index untouched.

        Args:
            df: The data frame to remove the columns from.
            data_set: The name of the data set with columns to preserve.
            any_data_set: Whether to remove all columns that are not in any data set.

        Returns:
            The data frame is only the data set columns.
        &#34;&#34;&#34;
        if any_data_set and data_set is not None:
            raise ValueError(&#39;Either data_set can be provide or any_data_set can be True but not both.&#39;)

        ds_cols = list(self.df(data_set, any_data_set)[&#39;Name&#39;].values)
        df_cols = [v for v in df.columns if v in ds_cols]
        return df[df_cols]

    def add_stats(self, df: pd.DataFrame) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Adds the `Total` and `Average` of the column values as two rows at the top of the data frame.

        Args:
            df: The data frame to summarise.

        Returns:
            The data frame with the `Total` and `Average` at the top.
        &#34;&#34;&#34;
        if df is None: raise ValueError(&#39;Parameter df is mandatory&#39;)

        num_agg_map = {col: DataDict.stats.keys() for col in df if is_numeric_dtype(df[col]) and df[col].dtype != np.bool}
        aggr_row = df.agg(num_agg_map).rename(DataDict.stats)
        if len(df.index.names) &gt; 1:
            aggr_row = pd.concat([aggr_row], keys=[np.nan] * len(DataDict.stats.keys()), names=df.index.names[1:])
        df = pd.concat([df.iloc[:0], aggr_row, df], sort=False)

        # Adds the dictionary of stats to the data frame.
        if not hasattr(df, &#39;stats&#39;):
            with warnings.catch_warnings():
                warnings.simplefilter(&#34;ignore&#34;)
                df.stats = {}

        df.stats = {**df.stats, **DataDict.stats}

        return df

    def has_stats(self, df: pd.DataFrame):
        &#34;&#34;&#34;
        Checks whether the given data frame has stats rows added at the top of the data frame.

        Args:
            df: The data frame to check.

        Returns:
            Whether the given data frame has stats.
        &#34;&#34;&#34;
        return hasattr(df, &#39;stats&#39;)

    def format(self, df: pd.DataFrame) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Formats the data frame based on the `Format` attribute in the data dictionary.

        Args:
            df: The data frame to format.

        Returns:
            The formatted data frame.
        &#34;&#34;&#34;
        if df is None: raise ValueError(&#39;Parameter df is mandatory&#39;)

        # Necessary to define separate function instead of using lambda directly (see https://stackoverflow.com/questions/36805071/dictionary-comprehension-with-lambda-functions-gives-wrong-results)
        def make_func(f: str = None):
            def format_value(x):
                if f is None or f == &#39;&#39;:
                    return x if not pd.isnull(x) else &#39;-&#39;

                return f.format(x) if not pd.isnull(x) else &#39;-&#39;

            # If mean is part of the stats, then the integer numbers need to be formatted as floats because the mean of integers can be float.
            if self.has_stats(df) and &#39;mean&#39; in df.stats.keys() and not f is None:
                f = f.replace(&#39;:d&#39;, &#39;:.1f&#39;)

            return lambda x: format_value(x)

        # Assembles a dictionary with columns as key and format functions as values but only for the columns that are actually in the data frame.
        formats = {col: make_func(f) for (col, f) in self._formats.items() if col in df.columns.values}
        formats = {**formats, **{col: make_func() for col in set(df.columns.values) - set(self._formats.keys())}}

        df = df.copy()
        for col, value in formats.items():
            try:
                df[col] = df[col].apply(value)
            except ValueError as e:
                warnings.warn(f&#39;A value in column {col} could not be formatted.\nError message: {e}&#39;)

        return df</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="datadict.DataDict.column_names"><code class="name">var <span class="ident">column_names</span></code></dt>
<dd>
<section class="desc"><p>list() -&gt; new empty list
list(iterable) -&gt; new list initialized from iterable's items</p></section>
</dd>
<dt id="datadict.DataDict.meta"><code class="name">var <span class="ident">meta</span></code></dt>
<dd>
<section class="desc"><p>This class provides functionality for mapping the columns of different data frames into a consistent namespace,
ensuring the columns to comply with the data type specified in the data dictionary and describing the data.</p>
<p>The data dictionary consists at least of the following columns:
* <code>Data Set</code>: Used when mapping in combination with <code>Field</code> to rename to the column to <code>Name</code>.
* <code>Field</code>: Column name of the data frame to map to <code>Name</code>.
* <code>Name</code>: Column name that is unique throughout the data dictionary.
* <code>Description</code>: Description of the column name. This can be used to provide additional information when displaying the data frame.
* <code>Type</code>: Type the column should be cast to.
* <code>Format</code>: Format to use when values need to be converted to a string representation. The format string has to be a Python format string such as <code>{:.0f}%</code></p>
<p>The data dictionary can either be loaded from a CSV file or from a data frame.</p></section>
</dd>
<dt id="datadict.DataDict.stats"><code class="name">var <span class="ident">stats</span></code></dt>
<dd>
<section class="desc"><p>dict() -&gt; new empty dictionary
dict(mapping) -&gt; new dictionary initialized from a mapping object's
(key, value) pairs
dict(iterable) -&gt; new dictionary initialized as if via:
d = {}
for k, v in iterable:
d[k] = v
dict(**kwargs) -&gt; new dictionary initialized with the name=value pairs
in the keyword argument list.
For example:
dict(one=1, two=2)</p></section>
</dd>
<dt id="datadict.DataDict.supported_types"><code class="name">var <span class="ident">supported_types</span></code></dt>
<dd>
<section class="desc"><p>list() -&gt; new empty list
list(iterable) -&gt; new list initialized from iterable's items</p></section>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="datadict.DataDict.validate"><code class="name flex">
<span>def <span class="ident">validate</span></span>(<span>data_dict)</span>
</code></dt>
<dd>
<section class="desc"><p>Validates the given data dictionary and raises a <code>ValueError</code> if the validation fails.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data_dict</code></strong></dt>
<dd>The data dictionary to validate.</dd>
</dl>
<p>Returns:</p>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>ValueError</code></strong></dt>
<dd>If the given data dictionary is not valid.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def validate(data_dict: pd.DataFrame) -&gt; None:
    &#34;&#34;&#34;
    Validates the given data dictionary and raises a `ValueError` if the validation fails.

    Args:
        data_dict: The data dictionary to validate.

    Returns:

    Raises:
        ValueError: If the given data dictionary is not valid.
    &#34;&#34;&#34;
    if data_dict is None:
        return

    data_dict = data_dict.copy()

    # Check that all expected columns exist.
    if not set(data_dict.columns) &gt;= set(DataDict.column_names):
        raise ValueError(f&#39;The data dictionary must at least include the following column names: {DataDict.column_names}&#39;)

    # Check that all types are supported Python types.
    if not set(data_dict[&#39;Type&#39;].values) &lt;= set(DataDict.supported_types):
        raise ValueError(
            f&#39;The Type column of the data dictionary contains the following unsupported types {set(data_dict[&#34;Type&#34;].values) - set(DataDict.supported_types)}. Only the following types are supported: {DataDict.supported_types}&#39;)

    # Check that names are unique.
    if any(data_dict[&#39;Name&#39;].duplicated()):
        raise ValueError(f&#39;The Name column contains the following duplicates: {data_dict[&#34;Name&#34;][data_dict[&#34;Name&#34;].duplicated()].values}. The names must be unique.&#39;)

    # Check that dataset and field combination is unique.
    data_dict = data_dict.replace(&#39;&#39;, np.nan)
    data_dict[&#39;Field ID&#39;] = data_dict[&#39;Data Set&#39;] + &#39;.&#39; + data_dict[&#39;Field&#39;]
    if any(data_dict[&#39;Field ID&#39;][data_dict[&#39;Field ID&#39;].isnull() == False].duplicated()):
        raise ValueError(f&#39;The combination of columns Data Set and Field contains the following duplicates: {data_dict[&#34;Field ID&#34;][data_dict[&#34;Field ID&#34;].duplicated()].values}. The combination must be unique.&#39;)</code></pre>
</details>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="datadict.DataDict.data_dict"><code class="name">var <span class="ident">data_dict</span></code></dt>
<dd>
<section class="desc"><p>Data dictionary as a data frame.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def data_dict(self) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Data dictionary as a data frame.
    &#34;&#34;&#34;
    return self._data_dict</code></pre>
</details>
</dd>
<dt id="datadict.DataDict.formats"><code class="name">var <span class="ident">formats</span></code></dt>
<dd>
<section class="desc"><p>Dictionary that maps the columns to names to their format strings.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def formats(self) -&gt; Dict[str, str]:
    &#34;&#34;&#34;
    Dictionary that maps the columns to names to their format strings.
    &#34;&#34;&#34;
    return self._formats</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="datadict.DataDict.add_stats"><code class="name flex">
<span>def <span class="ident">add_stats</span></span>(<span>self, df)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds the <code>Total</code> and <code>Average</code> of the column values as two rows at the top of the data frame.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>df</code></strong></dt>
<dd>The data frame to summarise.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The data frame with the <code>Total</code> and <code>Average</code> at the top.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_stats(self, df: pd.DataFrame) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Adds the `Total` and `Average` of the column values as two rows at the top of the data frame.

    Args:
        df: The data frame to summarise.

    Returns:
        The data frame with the `Total` and `Average` at the top.
    &#34;&#34;&#34;
    if df is None: raise ValueError(&#39;Parameter df is mandatory&#39;)

    num_agg_map = {col: DataDict.stats.keys() for col in df if is_numeric_dtype(df[col]) and df[col].dtype != np.bool}
    aggr_row = df.agg(num_agg_map).rename(DataDict.stats)
    if len(df.index.names) &gt; 1:
        aggr_row = pd.concat([aggr_row], keys=[np.nan] * len(DataDict.stats.keys()), names=df.index.names[1:])
    df = pd.concat([df.iloc[:0], aggr_row, df], sort=False)

    # Adds the dictionary of stats to the data frame.
    if not hasattr(df, &#39;stats&#39;):
        with warnings.catch_warnings():
            warnings.simplefilter(&#34;ignore&#34;)
            df.stats = {}

    df.stats = {**df.stats, **DataDict.stats}

    return df</code></pre>
</details>
</dd>
<dt id="datadict.DataDict.auto_reload"><code class="name flex">
<span>def <span class="ident">auto_reload</span></span>(<span>func)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def auto_reload(func):
    @functools.wraps(func)
    def wrapper(self, *args, **kwargs):
        if self.auto_reload:
            self.__load()

        return func(self, *args, **kwargs)

    return wrapper</code></pre>
</details>
</dd>
<dt id="datadict.DataDict.df"><code class="name flex">
<span>def <span class="ident">df</span></span>(<span>self, data_set=None, any_data_set=False)</span>
</code></dt>
<dd>
<section class="desc"><p>Gets the data set with the given name as a data frame.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data_set</code></strong></dt>
<dd>The data set to filter by. If this value matches a value in the <code>Data Set</code> column of the data dictionary, the matching rows are returned.</dd>
<dt>If <code>data_set</code> is not specified, the entries with empty <code>Data Set</code> are returned.</dt>
<dt><strong><code>any_data_set</code></strong></dt>
<dd>Whether to return all data sets in the data frame.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The data set as a data frame, index by the <code>Field</code> column.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def df(self, data_set: str = None, any_data_set: bool = False) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Gets the data set with the given name as a data frame.

    Args:
        data_set: The data set to filter by. If this value matches a value in the `Data Set` column of the data dictionary, the matching rows are returned.
        If `data_set` is not specified, the entries with empty `Data Set` are returned.
        any_data_set: Whether to return all data sets in the data frame.

    Returns:
        The data set as a data frame, index by the `Field` column.
    &#34;&#34;&#34;
    if any_data_set and data_set is not None:
        raise ValueError(&#39;Either data_set can be provide or any_data_set can be True but not both.&#39;)

    if data_set is None: data_set = &#39;&#39;

    return self._data_dict[(self._data_dict[&#39;Data Set&#39;] == data_set) | any_data_set].set_index(&#39;Field&#39;)</code></pre>
</details>
</dd>
<dt id="datadict.DataDict.ensure_cols"><code class="name flex">
<span>def <span class="ident">ensure_cols</span></span>(<span>self, df, cols=None, data_set=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Ensures that the columns from the given data set or the given columns names are present the resulting data frame. Missing columns are added at the end.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>df</code></strong></dt>
<dd>The data frame to add the missing columns (if any) to.</dd>
<dt><strong><code>data_set</code></strong></dt>
<dd>The name of data set to use. If this value matches a value in the <code>Data Set</code> column of the data dictionary, then <code>Name</code> column is used to identify missing columns. If <code>dataset</code> is not specified, the values in <code>Name</code> column
that have entries with empty <code>Data Set</code> are used.</dd>
<dt><strong><code>cols</code></strong></dt>
<dd>The column names to ensure are present in the returned data frame.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The data frame with missing columns added to the end.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@auto_reload
def ensure_cols(self, df: pd.DataFrame, cols: list = None, data_set: str = None) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Ensures that the columns from the given data set or the given columns names are present the resulting data frame. Missing columns are added at the end.

    Args:
        df: The data frame to add the missing columns (if any) to.
        data_set: The name of data set to use. If this value matches a value in the `Data Set` column of the data dictionary, then `Name` column is used to identify missing columns. If `dataset` is not specified, the values in `Name` column
            that have entries with empty `Data Set` are used.
        cols: The column names to ensure are present in the returned data frame.

    Returns:
        The data frame with missing columns added to the end.
    &#34;&#34;&#34;
    if cols is not None and data_set is not None:
        raise ValueError(&#39;Either the cols or the data_set arguments can be provided but not both.&#39;)

    if cols is None:
        cols = list(self.df(data_set)[&#39;Name&#39;].values)

    current_cols = list(df.columns.values)+list(df.index.names)
    missing_cols = [v for v in cols if v not in current_cols]
    return df.reindex(columns=(list(df.columns.values)+missing_cols))</code></pre>
</details>
</dd>
<dt id="datadict.DataDict.format"><code class="name flex">
<span>def <span class="ident">format</span></span>(<span>self, df)</span>
</code></dt>
<dd>
<section class="desc"><p>Formats the data frame based on the <code>Format</code> attribute in the data dictionary.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>df</code></strong></dt>
<dd>The data frame to format.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The formatted data frame.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def format(self, df: pd.DataFrame) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Formats the data frame based on the `Format` attribute in the data dictionary.

    Args:
        df: The data frame to format.

    Returns:
        The formatted data frame.
    &#34;&#34;&#34;
    if df is None: raise ValueError(&#39;Parameter df is mandatory&#39;)

    # Necessary to define separate function instead of using lambda directly (see https://stackoverflow.com/questions/36805071/dictionary-comprehension-with-lambda-functions-gives-wrong-results)
    def make_func(f: str = None):
        def format_value(x):
            if f is None or f == &#39;&#39;:
                return x if not pd.isnull(x) else &#39;-&#39;

            return f.format(x) if not pd.isnull(x) else &#39;-&#39;

        # If mean is part of the stats, then the integer numbers need to be formatted as floats because the mean of integers can be float.
        if self.has_stats(df) and &#39;mean&#39; in df.stats.keys() and not f is None:
            f = f.replace(&#39;:d&#39;, &#39;:.1f&#39;)

        return lambda x: format_value(x)

    # Assembles a dictionary with columns as key and format functions as values but only for the columns that are actually in the data frame.
    formats = {col: make_func(f) for (col, f) in self._formats.items() if col in df.columns.values}
    formats = {**formats, **{col: make_func() for col in set(df.columns.values) - set(self._formats.keys())}}

    df = df.copy()
    for col, value in formats.items():
        try:
            df[col] = df[col].apply(value)
        except ValueError as e:
            warnings.warn(f&#39;A value in column {col} could not be formatted.\nError message: {e}&#39;)

    return df</code></pre>
</details>
</dd>
<dt id="datadict.DataDict.has_stats"><code class="name flex">
<span>def <span class="ident">has_stats</span></span>(<span>self, df)</span>
</code></dt>
<dd>
<section class="desc"><p>Checks whether the given data frame has stats rows added at the top of the data frame.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>df</code></strong></dt>
<dd>The data frame to check.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Whether the given data frame has stats.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def has_stats(self, df: pd.DataFrame):
    &#34;&#34;&#34;
    Checks whether the given data frame has stats rows added at the top of the data frame.

    Args:
        df: The data frame to check.

    Returns:
        Whether the given data frame has stats.
    &#34;&#34;&#34;
    return hasattr(df, &#39;stats&#39;)</code></pre>
</details>
</dd>
<dt id="datadict.DataDict.remap"><code class="name flex">
<span>def <span class="ident">remap</span></span>(<span>self, df, data_set=None, ensure_cols=False)</span>
</code></dt>
<dd>
<section class="desc"><p>Renames the columns in the given data frame based on based on the <code>Data Set</code> and <code>Field</code> attributes in the data dictionary to <code>Name</code>
if such a mapping found and converts the columns data to <code>Type</code>. It also reorders the columns based on the order of the data dictionary entries.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>df</code></strong></dt>
<dd>The data frame to remap.</dd>
<dt><strong><code>data_set</code></strong></dt>
<dd>The data set to use. If this value matches a value in the <code>Data Set</code> column of the data dictionary, then the corresponding names in the <code>Field</code>
column are used to rename the columns of the given data frame to the <code>Name</code> column name. If <code>dataset</code> is not specified, the values in <code>Field</code> column
that have entries with empty <code>Data Set</code> are used.</dd>
<dt><strong><code>ensure_cols</code></strong></dt>
<dd>Ensures all columns in the data_set are present. If the source data frame does not contain them, empty ones are created. This parameter can
only be true if data_set is specified. This is useful when the data frame to be remapped may not have all the columns if it is empty.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The remapped data frame.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@auto_reload
def remap(self, df: pd.DataFrame, data_set: str = None, ensure_cols: bool = False) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Renames the columns in the given data frame based on based on the `Data Set` and `Field` attributes in the data dictionary to `Name`
    if such a mapping found and converts the columns data to `Type`. It also reorders the columns based on the order of the data dictionary entries.

    Args:
        df: The data frame to remap.
        data_set: The data set to use. If this value matches a value in the `Data Set` column of the data dictionary, then the corresponding names in the `Field`
            column are used to rename the columns of the given data frame to the `Name` column name. If `dataset` is not specified, the values in `Field` column
            that have entries with empty `Data Set` are used.
        ensure_cols: Ensures all columns in the data_set are present. If the source data frame does not contain them, empty ones are created. This parameter can
            only be true if data_set is specified. This is useful when the data frame to be remapped may not have all the columns if it is empty.

    Returns:
        The remapped data frame.
    &#34;&#34;&#34;
    if df is None:
        raise ValueError(&#39;Parameter df not provided.&#39;)

    if (data_set is None or data_set == &#39;&#39;) and ensure_cols:
        raise ValueError(&#39;Parameter data_set cannot be None or empty if ensure_cols is True.&#39;)

    dd = self.df(data_set)

    # Ensure that nan is represented as None so that column type conversion does not result in object types if nan is present.
    df = df.replace(&#39;&#39;, np.nan)

    types_map = dd[&#39;Type&#39;].to_dict()
    types_map = {col: type for (col, type) in types_map.items() if col in df.columns}  # Remove mapping for columns that are not present in data frame.

    # Treat bool separately &#39;cause all non-empty strings are converted to True.
    # Map values of non-bool columns using data type.
    no_bool_types_map = {col: type for (col, type) in types_map.items() if type != &#39;bool&#39;}
    df = df.astype(no_bool_types_map, errors=&#39;ignore&#39;)

    # Map values of bool columns using data type.
    bool_cols = [col for (col, type) in types_map.items() if type == &#39;bool&#39;]
    df[bool_cols] = df[bool_cols].apply(lambda col: col.map(lambda val: self.__str_to_bool(val)))

    columns_map = dd[&#39;Name&#39;].to_dict()
    df = df.rename(columns=columns_map)
    df = self.reorder(df)

    if ensure_cols:
        df = self.ensure_cols(df, data_set=data_set)

    return df</code></pre>
</details>
</dd>
<dt id="datadict.DataDict.reorder"><code class="name flex">
<span>def <span class="ident">reorder</span></span>(<span>self, df)</span>
</code></dt>
<dd>
<section class="desc"><p>Reorders the given data frame based on the order of the matching entries in the data dictionary.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>df</code></strong></dt>
<dd>The data frame whose columns need to be reordered.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The reordered data frame.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@auto_reload
def reorder(self, df: pd.DataFrame) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Reorders the given data frame based on the order of the matching entries in the data dictionary.

    Args:
        df: The data frame whose columns need to be reordered.

    Returns:
        The reordered data frame.
    &#34;&#34;&#34;
    return df[[x for x in self._names if x in list(df.columns.values)]
              + [x for x in list(df.columns.values) if x not in self._names]]</code></pre>
</details>
</dd>
<dt id="datadict.DataDict.strip_cols"><code class="name flex">
<span>def <span class="ident">strip_cols</span></span>(<span>self, df, data_set=None, any_data_set=False)</span>
</code></dt>
<dd>
<section class="desc"><p>Removes all columns that are not in the given data set from the given data frame or all columns that are not in any data set. It leaves
the index untouched.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>df</code></strong></dt>
<dd>The data frame to remove the columns from.</dd>
<dt><strong><code>data_set</code></strong></dt>
<dd>The name of the data set with columns to preserve.</dd>
<dt><strong><code>any_data_set</code></strong></dt>
<dd>Whether to remove all columns that are not in any data set.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The data frame is only the data set columns.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@auto_reload
def strip_cols(self, df: pd.DataFrame, data_set: str = None, any_data_set: bool = False):
    &#34;&#34;&#34;
    Removes all columns that are not in the given data set from the given data frame or all columns that are not in any data set. It leaves
    the index untouched.

    Args:
        df: The data frame to remove the columns from.
        data_set: The name of the data set with columns to preserve.
        any_data_set: Whether to remove all columns that are not in any data set.

    Returns:
        The data frame is only the data set columns.
    &#34;&#34;&#34;
    if any_data_set and data_set is not None:
        raise ValueError(&#39;Either data_set can be provide or any_data_set can be True but not both.&#39;)

    ds_cols = list(self.df(data_set, any_data_set)[&#39;Name&#39;].values)
    df_cols = [v for v in df.columns if v in ds_cols]
    return df[df_cols]</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="datadict.jupyter" href="jupyter/index.html">datadict.jupyter</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="datadict.DataDict" href="#datadict.DataDict">DataDict</a></code></h4>
<ul class="two-column">
<li><code><a title="datadict.DataDict.add_stats" href="#datadict.DataDict.add_stats">add_stats</a></code></li>
<li><code><a title="datadict.DataDict.auto_reload" href="#datadict.DataDict.auto_reload">auto_reload</a></code></li>
<li><code><a title="datadict.DataDict.column_names" href="#datadict.DataDict.column_names">column_names</a></code></li>
<li><code><a title="datadict.DataDict.data_dict" href="#datadict.DataDict.data_dict">data_dict</a></code></li>
<li><code><a title="datadict.DataDict.df" href="#datadict.DataDict.df">df</a></code></li>
<li><code><a title="datadict.DataDict.ensure_cols" href="#datadict.DataDict.ensure_cols">ensure_cols</a></code></li>
<li><code><a title="datadict.DataDict.format" href="#datadict.DataDict.format">format</a></code></li>
<li><code><a title="datadict.DataDict.formats" href="#datadict.DataDict.formats">formats</a></code></li>
<li><code><a title="datadict.DataDict.has_stats" href="#datadict.DataDict.has_stats">has_stats</a></code></li>
<li><code><a title="datadict.DataDict.meta" href="#datadict.DataDict.meta">meta</a></code></li>
<li><code><a title="datadict.DataDict.remap" href="#datadict.DataDict.remap">remap</a></code></li>
<li><code><a title="datadict.DataDict.reorder" href="#datadict.DataDict.reorder">reorder</a></code></li>
<li><code><a title="datadict.DataDict.stats" href="#datadict.DataDict.stats">stats</a></code></li>
<li><code><a title="datadict.DataDict.strip_cols" href="#datadict.DataDict.strip_cols">strip_cols</a></code></li>
<li><code><a title="datadict.DataDict.supported_types" href="#datadict.DataDict.supported_types">supported_types</a></code></li>
<li><code><a title="datadict.DataDict.validate" href="#datadict.DataDict.validate">validate</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>